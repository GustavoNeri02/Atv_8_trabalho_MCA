#Scrapping in "pdf" com python?
    PyPDF2 --> https://pypi.org/project/PyPDF2/
     - Consigo obter o text do pdf. 
     >  Uma possível solução seria vazer uma varredura por regexs nesse texto.

    transformar informações do pdf em um "csv" para utilzar métodos "web scrapping"

    -> instalar:
        tabula-py

#Web Scrapping?
    1o. acessar páginda da FAPEG; > --deprecated --> inicie da segunda etapa
    2o. acessar seção de editais; > "http://www.fapeg.go.gov.br/categoria/editais/"
    3o. da lista de editais, acessar suas páginas;
    4o. para cada pagina, baixar o(s) arquivos de edital correspondente(s). > wget?
    5o. complementando o 4o objetivo:
        -> guardar as informações da página e os arquivos encontrados. > [xlsx || csv] formato dos dados

    #pdf puro e seco: abre página... pá, só tem edital.


> gerenciamento da arquitetura do programa
# data :
|-> # scrapping (arquivos e referencia dos dados - contexto de acesso web)
\-> # extracting (arquivos e referencia dos dados - contexto de processamento dos dados)
# src :
| * main.py
| * Constants.py 
\-> # scrapping
    | * ws_bot.py
    | * pdf_reader.py
    | * table_organizer.py
    \ * user_system.py


#apresentação de resultados em gráficos:
    1o criar uma classe para gerenciar a funcionalidade
    2o a classe gerenciadora recebe e armazena por vezes diferentes deferencias do processo do ws_bot
    3o caso 1: a quantidade de arquivos encontrados por pagina de edital (quantidade de artigos)
    4o caso 2: a quantidade de editais (chamada pública) segundo data de publicação
    

    apresentações dos dados (cronograma):
    -> lançamento
    -> submissão / inscrições / inscrição
    -> resultado
    -> <última data>